{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. 자연어와 단어의 분산 표현\n",
    "\n",
    "> 딥러닝 등장 이전에의 쓰이던 고전 기법들에 대한 소개\n",
    "\n",
    "\n",
    "### 자연어 처리\n",
    "> 우리의 말을 컴퓨터에게 이해시키기 위한 기술(분야) <br/><br/>\n",
    "> **응용 분야** <br/>\n",
    "> 검색 엔진, 기계 번역, 질의응답 시스템, IME(입력기 전환), 문장 자동요약, 감정 분석\n",
    "\n",
    "### 단어의 의미\n",
    "> '문자' - 말 <br/>\n",
    "> '단어' - 말의 의미 <br/>\n",
    "> **단어는 의미를 이루는 최소단위이다.**\n",
    "\n",
    "### 시소러스 기반 기법 (by Human)\n",
    "> 유의어 사전, 유의어나 동의어가 한 분류로 분류되어 있다. <br/>\n",
    "> - **자연어 처리에서의 시소러스는 '상위/하위', '전체/부분' 등 더 세세한 관계를 정의** <br/>\n",
    "> - 단어들의 관계를 그래프로 표현하여 단어의 연결을 정의 (단어 네트워크) <br/>\n",
    "> - **WordNet** : 프리스턴 대학교에서 1985년 부터 구축하기 시작한 NLP 분야에서 가장 유명한 시소러스\n",
    "> - **문제점** : 시대 변화에 대한 대응이 어려움(신조어 및 바뀌는 단어의 의미), 큰 인적 비용 발생, 미묘한 차이(용법)를 표현할 방법 없음.\n",
    "\n",
    "### 통계 기반 기법\n",
    "> '말뭉치(corpus)' - 대량의 텍스트 데이터, 주로 자연어 처리나 응용을 염두해두고 모은 데이터 <br/>\n",
    "> **목표** : 사람의 지식으로 가득한 말뭉치에서 자동으로, 효율적으로 그 핵심을 추출하는 것. <br/>\n",
    "> 추가 레이블(품사와 같은 추가 정보가 컴퓨터가 이해하기 좋은 이진 형태로 레이블링)이 구성될 수 있으나 이 책에서는 추가 레이블 없는 큰 말뭉치가 있다는 가정하에 진행할 것임.\n",
    "\n",
    "### 파이썬으로 말뭉치 전처리(Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'was', 'a', 'car', 'and', 'you', 'drived', 'that', 'car', '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'I was a car and you drived that car.'\n",
    "txt = txt.lower() # 문장의 첫머리도 똑같이 취급하기 위해 모두 소문자화 하기\n",
    "txt = txt.replace('.',' .') # 마침표 고려 - 공백열 + 온점으로 바꿈\n",
    "words1 = txt.split(' ') # 공백열 기준으로 분할\n",
    "words1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 단어를 분할 할 때, 정규표현식 모듈인 re를 import 하여 단어 분할을 실행할 수도 있음.ㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " None,\n",
       " 'i',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'w',\n",
       " None,\n",
       " 'a',\n",
       " None,\n",
       " 's',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'a',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'c',\n",
       " None,\n",
       " 'a',\n",
       " None,\n",
       " 'r',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'a',\n",
       " None,\n",
       " 'n',\n",
       " None,\n",
       " 'd',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'y',\n",
       " None,\n",
       " 'o',\n",
       " None,\n",
       " 'u',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'd',\n",
       " None,\n",
       " 'r',\n",
       " None,\n",
       " 'i',\n",
       " None,\n",
       " 'v',\n",
       " None,\n",
       " 'e',\n",
       " None,\n",
       " 'd',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 't',\n",
       " None,\n",
       " 'h',\n",
       " None,\n",
       " 'a',\n",
       " None,\n",
       " 't',\n",
       " ' ',\n",
       " '',\n",
       " None,\n",
       " 'c',\n",
       " None,\n",
       " 'a',\n",
       " None,\n",
       " 'r',\n",
       " '.',\n",
       " '',\n",
       " None,\n",
       " '']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = 'I was a car and you drived that car.'\n",
    "txt = txt.lower()\n",
    "words2 = re.split('(\\W+)?', txt)\n",
    "words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words1:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 0,\n",
       " 'was': 1,\n",
       " 'a': 2,\n",
       " 'car': 3,\n",
       " 'and': 4,\n",
       " 'you': 5,\n",
       " 'drived': 6,\n",
       " 'that': 7,\n",
       " '.': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'i',\n",
       " 1: 'was',\n",
       " 2: 'a',\n",
       " 3: 'car',\n",
       " 4: 'and',\n",
       " 5: 'you',\n",
       " 6: 'drived',\n",
       " 7: 'that',\n",
       " 8: '.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'was'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 목록을 단어 ID 목록으로 변경해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.16.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 3, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words1]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리를 한데 모아!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 0, 8, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You and I are really happy to meet you guys.' # 말도 안대지만 you를 두번 쓰고 싶었음.\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0,\n",
       " 'and': 1,\n",
       " 'i': 2,\n",
       " 'are': 3,\n",
       " 'really': 4,\n",
       " 'happy': 5,\n",
       " 'to': 6,\n",
       " 'meet': 7,\n",
       " 'guys': 8,\n",
       " '.': 9}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you',\n",
       " 1: 'and',\n",
       " 2: 'i',\n",
       " 3: 'are',\n",
       " 4: 'really',\n",
       " 5: 'happy',\n",
       " 6: 'to',\n",
       " 7: 'meet',\n",
       " 8: 'guys',\n",
       " 9: '.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 분산 표현\n",
    "> - RGB 색상표 처럼 단어의 의미를 더 정확하게 파악할 수 있는 벡터 표현<br/>\n",
    "> - 단어를 고정 길이의 **밀집 벡터(dense vector)** 로 표현 <br/>\n",
    "> **밀집 벡터(dense vector)** : 원소가 0이 아닌 실수인 벡터\n",
    "> - **분포 가설(distributional hypothesis)** : 단어의 의미는 주변 단어에 의해 형성된다. 단어 자체에는 의미가 없지만 그 단어가 사용된 **맥락(context), 즉 주변 단어** 가 의미를 형성<br/>\n",
    "> - 맥락의 크기 == 윈도우 크기(windwo size)\n",
    "> **ex)** You and I are really happy to meet you guys. <br/>\n",
    "> **퀘-스천!** 만약 'happy'를 기준으로 윈도우 크기가 2라면?\n",
    "\n",
    "### 동시발생 행렬\n",
    "> 어떤 단어가 몇번이나 등장했는가? 세어서 집계 <br/>\n",
    "> **퀘-스천!** 만약 'you'를 기준으로 산정한다면? <br/>\n",
    "> 냉-철한 엔지니어는 모든 것을 자동화 하지! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] +=1\n",
    "                \n",
    "                if right_idx < corpus_size:\n",
    "                    right_word_id = corpus[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                    \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 간 유사도 측정\n",
    "> 코사인 유사도(cosine similarity) 이용 <br/>\n",
    "> **두 벡터가 가리키는 방향이 얼마나 비슷한가?** <br/>\n",
    "> 1(같음) or -1(반대)\n",
    "<img src=\"data:image/png;base64,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\">\n",
    "> 벡터를 정규화 한 후에, 내적을 구함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2)) # numpy 배열이라고 가정\n",
    "    ny = y / np.sqrt(np.sum(y**2)) # numpy 배열이라고 가정\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오-노!\n",
    "> 제로 벡터가 들어오면 Divide by zero 오류가 발생<br/>\n",
    "> 분모에 작은 값을 더해줌으로써 해결! 매우 작은 값은 부동소수점 계산시 반올림 되어 다른 값에 흡수되어서 최종 계산 결과를 어지럽힐까 걱정 댓츠 노-노!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps =1e-8):\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps) # numpy 배열이라고 가정\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps) # numpy 배열이라고 가정\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사 단어의 랭킹 표시\n",
    "> 어떤 단어가 나랑 제일 인접할까(관계가 많을까)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    # 1. 검색어를 꺼낸다.\n",
    "    if query not in word_to_id:\n",
    "        print('$s(을)를 찾을 수 없습니다.' %query)\n",
    "        return\n",
    "    \n",
    "    print ('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 2. 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    # 3. 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query :\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기서 잠깐!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argsort() 메소드는 넘파이 배열의 원소를 오름차순으로 정렬\n",
    "x = np.array([100, -20, 2])\n",
    "x.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-x).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " .: 0.7071067758832467\n",
      " to: 0.49999999749999996\n",
      " and: 0.0\n",
      " i: 0.0\n",
      " are: 0.0\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계 기반 기법 개선하기\n",
    "> 상호정보량 : 단순히 빈도수가 높다고 해서 의미 있는 것은 아님. <br/>\n",
    "> - **점별 상호정보량(PMI : Pointwise Mutual Information)**\n",
    "> - **차원 감소**\n",
    "> - **PTB 데이터셋 평가**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
